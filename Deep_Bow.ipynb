{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Bow.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMORVfDkuVNSbmMtY4h3llp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tusharvatsa32/Language-Models/blob/main/Deep_Bow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBzxJFEy8B9e",
        "outputId": "3eb68cdf-ff32-4b1c-af8c-2d21ea2b28d6"
      },
      "source": [
        "!git clone https://github.com/tusharvatsa32/nn4nlp-code.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nn4nlp-code'...\n",
            "remote: Enumerating objects: 545, done.\u001b[K\n",
            "remote: Total 545 (delta 0), reused 0 (delta 0), pack-reused 545\u001b[K\n",
            "Receiving objects: 100% (545/545), 11.92 MiB | 19.18 MiB/s, done.\n",
            "Resolving deltas: 100% (217/217), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy2AHQul78xv",
        "outputId": "fd5a06db-c3a2-492a-fc30-35f212e825b0"
      },
      "source": [
        "pip install dynet"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dynet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/73/b5435275aa9b00f21a7aa7f50bb476a3768d6c0b9cfffde09b39035a7019/dyNET-2.1.2-cp36-cp36m-manylinux1_x86_64.whl (4.4MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5MB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from dynet) (0.29.21)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from dynet) (1.19.5)\n",
            "Installing collected packages: dynet\n",
            "Successfully installed dynet-2.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HUElVbB7xpg"
      },
      "source": [
        "from collections import defaultdict\n",
        "import time\n",
        "import random\n",
        "import dynet as dy\n",
        "import numpy as np\n",
        "\n",
        "# Functions to read in the corpus\n",
        "w2i = defaultdict(lambda: len(w2i))\n",
        "t2i = defaultdict(lambda: len(t2i))\n",
        "UNK = w2i[\"<unk>\"]\n",
        "def read_dataset(filename):\n",
        "  with open(filename, \"r\") as f:\n",
        "    for line in f:\n",
        "      tag, words = line.lower().strip().split(\" ||| \")\n",
        "      yield ([w2i[x] for x in words.split(\" \")], t2i[tag])\n",
        "\n",
        "# Read in the data\n",
        "train = list(read_dataset(\"nn4nlp-code/data/classes/train.txt\"))\n",
        "w2i = defaultdict(lambda: UNK, w2i)\n",
        "dev = list(read_dataset(\"nn4nlp-code/data/classes/test.txt\"))\n",
        "nwords = len(w2i)\n",
        "ntags = len(t2i)\n",
        "\n",
        "# Start DyNet and define trainer\n",
        "model = dy.Model()\n",
        "trainer = dy.AdamTrainer(model)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhEHkKVb77kb"
      },
      "source": [
        "EMB_SIZE = 64\n",
        "HID_SIZE = 64\n",
        "HID_LAY = 2\n",
        "W_emb = model.add_lookup_parameters((nwords, EMB_SIZE)) # Word embeddings\n",
        "W_h = [model.add_parameters((HID_SIZE, EMB_SIZE if lay == 0 else HID_SIZE)) for lay in range(HID_LAY)]\n",
        "b_h = [model.add_parameters((HID_SIZE)) for lay in range(HID_LAY)]\n",
        "W_sm = model.add_parameters((ntags, HID_SIZE))          # Softmax weights\n",
        "b_sm = model.add_parameters((ntags))                    # Softmax bias"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhF4W1-h76NF"
      },
      "source": [
        "def calc_scores(words):\n",
        "  dy.renew_cg()\n",
        "  h = dy.esum([dy.lookup(W_emb, x) for x in words])\n",
        "  for W_h_i, b_h_i in zip(W_h, b_h):\n",
        "    h = dy.tanh( dy.parameter(W_h_i) * h + dy.parameter(b_h_i) )\n",
        "  return dy.parameter(W_sm) * h + dy.parameter(b_sm)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdijeyFq72HE",
        "outputId": "34c35bcf-6998-4496-cd63-cdd2c80b48cf"
      },
      "source": [
        "for ITER in range(100):\n",
        "  # Perform training\n",
        "  random.shuffle(train)\n",
        "  train_loss = 0.0\n",
        "  start = time.time()\n",
        "  for words, tag in train:\n",
        "    my_loss = dy.pickneglogsoftmax(calc_scores(words), tag)\n",
        "    train_loss += my_loss.value()\n",
        "    my_loss.backward()\n",
        "    trainer.update()\n",
        "  print(\"iter %r: train loss/sent=%.4f, time=%.2fs\" % (ITER, train_loss/len(train), time.time()-start))\n",
        "  # Perform testing\n",
        "  test_correct = 0.0\n",
        "  for words, tag in dev:\n",
        "    scores = calc_scores(words).npvalue()\n",
        "    predict = np.argmax(scores)\n",
        "    if predict == tag:\n",
        "      test_correct += 1\n",
        "  print(\"iter %r: test acc=%.4f\" % (ITER, test_correct/len(dev)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The dy.parameter(...) call is now DEPRECATED.\n",
            "        There is no longer need to explicitly add parameters to the computation graph.\n",
            "        Any used parameter will be added automatically.\n",
            "iter 0: train loss/sent=1.5123, time=0.85s\n",
            "iter 0: test acc=0.3955\n",
            "iter 1: train loss/sent=1.1781, time=0.79s\n",
            "iter 1: test acc=0.4163\n",
            "iter 2: train loss/sent=0.8860, time=0.80s\n",
            "iter 2: test acc=0.4190\n",
            "iter 3: train loss/sent=0.6168, time=0.79s\n",
            "iter 3: test acc=0.4009\n",
            "iter 4: train loss/sent=0.4294, time=0.79s\n",
            "iter 4: test acc=0.3923\n",
            "iter 5: train loss/sent=0.3035, time=0.80s\n",
            "iter 5: test acc=0.3796\n",
            "iter 6: train loss/sent=0.2197, time=0.79s\n",
            "iter 6: test acc=0.3805\n",
            "iter 7: train loss/sent=0.1650, time=0.79s\n",
            "iter 7: test acc=0.3855\n",
            "iter 8: train loss/sent=0.1288, time=0.81s\n",
            "iter 8: test acc=0.3860\n",
            "iter 9: train loss/sent=0.1087, time=0.80s\n",
            "iter 9: test acc=0.3828\n",
            "iter 10: train loss/sent=0.0881, time=0.83s\n",
            "iter 10: test acc=0.3783\n",
            "iter 11: train loss/sent=0.0761, time=0.79s\n",
            "iter 11: test acc=0.3719\n",
            "iter 12: train loss/sent=0.0645, time=0.81s\n",
            "iter 12: test acc=0.3810\n",
            "iter 13: train loss/sent=0.0643, time=0.79s\n",
            "iter 13: test acc=0.3796\n",
            "iter 14: train loss/sent=0.0575, time=0.80s\n",
            "iter 14: test acc=0.3548\n",
            "iter 15: train loss/sent=0.0579, time=0.80s\n",
            "iter 15: test acc=0.3719\n",
            "iter 16: train loss/sent=0.0477, time=0.80s\n",
            "iter 16: test acc=0.3810\n",
            "iter 17: train loss/sent=0.0459, time=0.82s\n",
            "iter 17: test acc=0.3688\n",
            "iter 18: train loss/sent=0.0520, time=0.81s\n",
            "iter 18: test acc=0.3932\n",
            "iter 19: train loss/sent=0.0577, time=0.80s\n",
            "iter 19: test acc=0.3733\n",
            "iter 20: train loss/sent=0.0407, time=0.81s\n",
            "iter 20: test acc=0.3701\n",
            "iter 21: train loss/sent=0.0430, time=0.80s\n",
            "iter 21: test acc=0.3891\n",
            "iter 22: train loss/sent=0.0492, time=0.81s\n",
            "iter 22: test acc=0.3765\n",
            "iter 23: train loss/sent=0.0433, time=0.79s\n",
            "iter 23: test acc=0.3760\n",
            "iter 24: train loss/sent=0.0282, time=0.79s\n",
            "iter 24: test acc=0.3679\n",
            "iter 25: train loss/sent=0.0387, time=0.81s\n",
            "iter 25: test acc=0.3792\n",
            "iter 26: train loss/sent=0.0353, time=0.81s\n",
            "iter 26: test acc=0.3701\n",
            "iter 27: train loss/sent=0.0481, time=0.80s\n",
            "iter 27: test acc=0.3774\n",
            "iter 28: train loss/sent=0.0366, time=0.81s\n",
            "iter 28: test acc=0.3719\n",
            "iter 29: train loss/sent=0.0432, time=0.79s\n",
            "iter 29: test acc=0.3710\n",
            "iter 30: train loss/sent=0.0369, time=0.81s\n",
            "iter 30: test acc=0.3860\n",
            "iter 31: train loss/sent=0.0363, time=0.78s\n",
            "iter 31: test acc=0.3860\n",
            "iter 32: train loss/sent=0.0386, time=0.78s\n",
            "iter 32: test acc=0.3774\n",
            "iter 33: train loss/sent=0.0342, time=0.78s\n",
            "iter 33: test acc=0.3751\n",
            "iter 34: train loss/sent=0.0428, time=0.83s\n",
            "iter 34: test acc=0.4005\n",
            "iter 35: train loss/sent=0.0285, time=0.79s\n",
            "iter 35: test acc=0.3615\n",
            "iter 36: train loss/sent=0.0332, time=0.80s\n",
            "iter 36: test acc=0.3783\n",
            "iter 37: train loss/sent=0.0436, time=0.78s\n",
            "iter 37: test acc=0.3810\n",
            "iter 38: train loss/sent=0.0175, time=0.78s\n",
            "iter 38: test acc=0.3851\n",
            "iter 39: train loss/sent=0.0457, time=0.78s\n",
            "iter 39: test acc=0.3792\n",
            "iter 40: train loss/sent=0.0333, time=0.79s\n",
            "iter 40: test acc=0.3742\n",
            "iter 41: train loss/sent=0.0264, time=0.78s\n",
            "iter 41: test acc=0.3738\n",
            "iter 42: train loss/sent=0.0331, time=0.78s\n",
            "iter 42: test acc=0.3787\n",
            "iter 43: train loss/sent=0.0351, time=0.79s\n",
            "iter 43: test acc=0.3778\n",
            "iter 44: train loss/sent=0.0261, time=0.82s\n",
            "iter 44: test acc=0.3837\n",
            "iter 45: train loss/sent=0.0407, time=0.80s\n",
            "iter 45: test acc=0.3878\n",
            "iter 46: train loss/sent=0.0403, time=0.79s\n",
            "iter 46: test acc=0.3805\n",
            "iter 47: train loss/sent=0.0276, time=0.79s\n",
            "iter 47: test acc=0.3887\n",
            "iter 48: train loss/sent=0.0358, time=0.78s\n",
            "iter 48: test acc=0.3833\n",
            "iter 49: train loss/sent=0.0347, time=0.77s\n",
            "iter 49: test acc=0.3606\n",
            "iter 50: train loss/sent=0.0250, time=0.80s\n",
            "iter 50: test acc=0.3715\n",
            "iter 51: train loss/sent=0.0334, time=0.80s\n",
            "iter 51: test acc=0.3837\n",
            "iter 52: train loss/sent=0.0268, time=0.79s\n",
            "iter 52: test acc=0.3824\n",
            "iter 53: train loss/sent=0.0240, time=0.81s\n",
            "iter 53: test acc=0.3810\n",
            "iter 54: train loss/sent=0.0292, time=0.78s\n",
            "iter 54: test acc=0.3670\n",
            "iter 55: train loss/sent=0.0323, time=0.77s\n",
            "iter 55: test acc=0.3955\n",
            "iter 56: train loss/sent=0.0272, time=0.78s\n",
            "iter 56: test acc=0.3932\n",
            "iter 57: train loss/sent=0.0270, time=0.79s\n",
            "iter 57: test acc=0.3733\n",
            "iter 58: train loss/sent=0.0295, time=0.77s\n",
            "iter 58: test acc=0.3914\n",
            "iter 59: train loss/sent=0.0276, time=0.79s\n",
            "iter 59: test acc=0.3964\n",
            "iter 60: train loss/sent=0.0257, time=0.79s\n",
            "iter 60: test acc=0.3946\n",
            "iter 61: train loss/sent=0.0324, time=0.78s\n",
            "iter 61: test acc=0.3724\n",
            "iter 62: train loss/sent=0.0254, time=0.80s\n",
            "iter 62: test acc=0.3796\n",
            "iter 63: train loss/sent=0.0237, time=0.78s\n",
            "iter 63: test acc=0.3923\n",
            "iter 64: train loss/sent=0.0369, time=0.77s\n",
            "iter 64: test acc=0.3824\n",
            "iter 65: train loss/sent=0.0261, time=0.79s\n",
            "iter 65: test acc=0.3873\n",
            "iter 66: train loss/sent=0.0234, time=0.79s\n",
            "iter 66: test acc=0.3729\n",
            "iter 67: train loss/sent=0.0252, time=0.78s\n",
            "iter 67: test acc=0.3792\n",
            "iter 68: train loss/sent=0.0302, time=0.80s\n",
            "iter 68: test acc=0.3833\n",
            "iter 69: train loss/sent=0.0227, time=0.78s\n",
            "iter 69: test acc=0.3769\n",
            "iter 70: train loss/sent=0.0303, time=0.77s\n",
            "iter 70: test acc=0.3760\n",
            "iter 71: train loss/sent=0.0287, time=0.78s\n",
            "iter 71: test acc=0.3977\n",
            "iter 72: train loss/sent=0.0246, time=0.79s\n",
            "iter 72: test acc=0.3842\n",
            "iter 73: train loss/sent=0.0187, time=0.78s\n",
            "iter 73: test acc=0.3805\n",
            "iter 74: train loss/sent=0.0374, time=0.78s\n",
            "iter 74: test acc=0.3828\n",
            "iter 75: train loss/sent=0.0269, time=0.77s\n",
            "iter 75: test acc=0.3760\n",
            "iter 76: train loss/sent=0.0281, time=0.77s\n",
            "iter 76: test acc=0.3846\n",
            "iter 77: train loss/sent=0.0290, time=0.78s\n",
            "iter 77: test acc=0.3733\n",
            "iter 78: train loss/sent=0.0275, time=0.80s\n",
            "iter 78: test acc=0.3792\n",
            "iter 79: train loss/sent=0.0219, time=0.78s\n",
            "iter 79: test acc=0.3733\n",
            "iter 80: train loss/sent=0.0254, time=0.78s\n",
            "iter 80: test acc=0.3964\n",
            "iter 81: train loss/sent=0.0371, time=0.78s\n",
            "iter 81: test acc=0.3597\n",
            "iter 82: train loss/sent=0.0254, time=0.79s\n",
            "iter 82: test acc=0.3719\n",
            "iter 83: train loss/sent=0.0236, time=0.77s\n",
            "iter 83: test acc=0.3824\n",
            "iter 84: train loss/sent=0.0326, time=0.78s\n",
            "iter 84: test acc=0.3814\n",
            "iter 85: train loss/sent=0.0236, time=0.78s\n",
            "iter 85: test acc=0.3575\n",
            "iter 86: train loss/sent=0.0201, time=0.77s\n",
            "iter 86: test acc=0.3683\n",
            "iter 87: train loss/sent=0.0307, time=0.77s\n",
            "iter 87: test acc=0.3805\n",
            "iter 88: train loss/sent=0.0223, time=0.77s\n",
            "iter 88: test acc=0.3624\n",
            "iter 89: train loss/sent=0.0226, time=0.78s\n",
            "iter 89: test acc=0.3801\n",
            "iter 90: train loss/sent=0.0312, time=0.78s\n",
            "iter 90: test acc=0.3661\n",
            "iter 91: train loss/sent=0.0250, time=0.77s\n",
            "iter 91: test acc=0.3796\n",
            "iter 92: train loss/sent=0.0270, time=0.76s\n",
            "iter 92: test acc=0.3778\n",
            "iter 93: train loss/sent=0.0192, time=0.76s\n",
            "iter 93: test acc=0.3719\n",
            "iter 94: train loss/sent=0.0344, time=0.80s\n",
            "iter 94: test acc=0.3670\n",
            "iter 95: train loss/sent=0.0253, time=0.77s\n",
            "iter 95: test acc=0.3824\n",
            "iter 96: train loss/sent=0.0237, time=0.78s\n",
            "iter 96: test acc=0.3787\n",
            "iter 97: train loss/sent=0.0250, time=0.80s\n",
            "iter 97: test acc=0.3891\n",
            "iter 98: train loss/sent=0.0289, time=0.77s\n",
            "iter 98: test acc=0.3855\n",
            "iter 99: train loss/sent=0.0217, time=0.77s\n",
            "iter 99: test acc=0.3846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jao_qlj8VSO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}